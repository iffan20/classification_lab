{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e043b2",
   "metadata": {},
   "source": [
    "## Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "One way to define the data science process is as follows:\n",
    "\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. \n",
    "\n",
    "---\n",
    "## Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11dda8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Correlation between handedness and dancing alone\n",
    "# Answer: Left-handed individuals are more likely to dance alone than right-handed individuals.\n",
    "\n",
    "# 2. Correlation between handedness and having handicrafts as a hobby\n",
    "# Answer: Right-handed individuals are more likely to have handicrafts as a hobby than left-handed individuals.\n",
    "\n",
    "# 3. Correlation between handedness and a preference for dangerous activities\n",
    "#. Answer: Left-handed individuals are more likely to enjoy dangerous activities than right-handed individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32144652",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### Read in the file titled \"data.csv\":\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a154e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e730059",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7cc7fbd-dd5d-40a3-9b39-799976ed4197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  country  fromgoogle  engnat  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1  ...       US           2       1   \n",
       "1   1   5   1   4   2   5   5   4   1    5  ...       CA           2       1   \n",
       "2   1   2   1   1   5   4   3   2   1    4  ...       NL           2       2   \n",
       "3   1   4   1   5   1   4   5   4   3    5  ...       US           2       1   \n",
       "4   5   1   5   1   5   1   5   1   3    1  ...       US           2       1   \n",
       "\n",
       "   age  education  gender  orientation  race  religion  hand  \n",
       "0   22          3       1            1     3         2     3  \n",
       "1   14          1       2            2     6         1     1  \n",
       "2   30          4       1            1     1         1     2  \n",
       "3   18          2       2            5     3         2     2  \n",
       "4   22          3       1            1     3         2     3  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b55b21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### Conduct background research:\n",
    "\n",
    "Domain knowledge is irreplaceable. Figuring out what information is relevant to a problem, or what data would be useful to gather, is a major part of any end-to-end data science project! For this lab, you'll be using a dataset that someone else has put together, rather than collecting the data yourself.\n",
    "\n",
    "Do some background research about personality and handedness. What features, if any, are likely to help you make good predictions? How well do you think you'll be able to model this? Write a few bullet points summarizing what you believe, and remember to cite external sources.\n",
    "\n",
    "You don't have to be exhaustive here. Do enough research to form an opinion, and then move on.\n",
    "\n",
    "> You'll be using the answers to Q1-Q44 for modeling; you can disregard other features, e.g. country, age, internet browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5eff1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1              int64\n",
       "Q2              int64\n",
       "Q3              int64\n",
       "Q4              int64\n",
       "Q5              int64\n",
       "Q6              int64\n",
       "Q7              int64\n",
       "Q8              int64\n",
       "Q9              int64\n",
       "Q10             int64\n",
       "Q11             int64\n",
       "Q12             int64\n",
       "Q13             int64\n",
       "Q14             int64\n",
       "Q15             int64\n",
       "Q16             int64\n",
       "Q17             int64\n",
       "Q18             int64\n",
       "Q19             int64\n",
       "Q20             int64\n",
       "Q21             int64\n",
       "Q22             int64\n",
       "Q23             int64\n",
       "Q24             int64\n",
       "Q25             int64\n",
       "Q26             int64\n",
       "Q27             int64\n",
       "Q28             int64\n",
       "Q29             int64\n",
       "Q30             int64\n",
       "Q31             int64\n",
       "Q32             int64\n",
       "Q33             int64\n",
       "Q34             int64\n",
       "Q35             int64\n",
       "Q36             int64\n",
       "Q37             int64\n",
       "Q38             int64\n",
       "Q39             int64\n",
       "Q40             int64\n",
       "Q41             int64\n",
       "Q42             int64\n",
       "Q43             int64\n",
       "Q44             int64\n",
       "introelapse     int64\n",
       "testelapse      int64\n",
       "country        object\n",
       "fromgoogle      int64\n",
       "engnat          int64\n",
       "age             int64\n",
       "education       int64\n",
       "gender          int64\n",
       "orientation     int64\n",
       "race            int64\n",
       "religion        int64\n",
       "hand            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "506b2513-c94d-46e0-b7f5-12824e3605fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()[data.isnull().sum()!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48523ef1-c188-4dfe-91ea-a814dc38ed0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4184, 56)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf0649",
   "metadata": {},
   "source": [
    "### Conduct exploratory data analysis on this dataset:\n",
    "\n",
    "If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process.\n",
    "\n",
    "You might use this section to perform data cleaning if you find it to be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dfaf7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :44]\n",
    "y= data['hand']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26e657",
   "metadata": {},
   "source": [
    "### Calculate and interpret the baseline accuracy rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ecc3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hand\n",
       "1    84.655832\n",
       "2    10.803059\n",
       "3     4.278203\n",
       "0     0.262906\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hand'].value_counts(normalize = True).mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70154b59-ae87-47a9-8309-2fcd6f44c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target should be 1,2,3 \n",
    "# So drop the row show 0\n",
    "data = data[data['hand']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc9884d-890a-42db-af10-586a4c1151e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hand\n",
       "1    84.878984\n",
       "2    10.831536\n",
       "3     4.289480\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hand'].value_counts(normalize = True).mul(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016bb4e",
   "metadata": {},
   "source": [
    "### Short answer questions:\n",
    "\n",
    "In this lab, you'll use K-nearest neighbors and logistic regression to model handedness based on psychological factors. \n",
    "\n",
    "Answer the following related questions; your answers may be in bullet points.\n",
    "\n",
    "#### Describe the difference between regression and classification problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4807bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "# Output : Continuous value\n",
    "# Loss functions: MSE, RMSE, MAE\n",
    "# Evaluation Metrics: R^2\n",
    "\n",
    "# Classification\n",
    "# Output : Discrete value\n",
    "# Evaluation Metrics: Accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7469aee",
   "metadata": {},
   "source": [
    "#### Considering $k$-nearest neighbors, describe the relationship between $k$ and the bias-variance tradeoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a758c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small k: Low bias, high variance (captures detail, risk of overfitting).\n",
    "# Large k: High bias, low variance (more stable, risk of underfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc66d6",
   "metadata": {},
   "source": [
    "#### Why do we often standardize predictor variables when using $k$-nearest neighbors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a175b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make accurate and balanced predictions, \n",
    "# To ensure that each feature contributes equally to the distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad52536",
   "metadata": {},
   "source": [
    "#### Do you think we should standardize the explanatory variables for this problem? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71ccc6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We donâ€™t need to standardize for this problem, as each variable has a similar scale for the distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6e09f",
   "metadata": {},
   "source": [
    "#### How do we settle on $k$ for a $k$-nearest neighbors model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c8aa87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mannually / Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fe4a8",
   "metadata": {},
   "source": [
    "#### What is the default type of regularization for logistic regression as implemented in scikit-learn? (You might [check the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b49dadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b117e3",
   "metadata": {},
   "source": [
    "#### Describe the relationship between the scikit-learn `LogisticRegression` argument `C` and regularization strength:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0bece7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# They have an inverse relationship.\n",
    "# Higher values of C (e.g., C = 10 or C = 100) mean weaker regularization.\n",
    "# Lower values of C (e.g., C = 0.1 or C = 0.01) mean stronger regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19a574",
   "metadata": {},
   "source": [
    "#### Describe the relationship between regularization strength and the bias-variance tradeoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82c2edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here:\n",
    "# Higher regularization strength \n",
    "# Reduces variance ---> avoid overfitting.\n",
    "# Increases bias --->  leading to underfitting\n",
    "\n",
    "# Lower regularization strength\n",
    "# Reduces bias ---> avoid underfitting.\n",
    "# Increases variance --->  leading to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7089674d",
   "metadata": {},
   "source": [
    "#### Logistic regression is considered more interpretable than $k$-nearest neighbors. Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf94e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression is based on a mathematical framework and provides coefficient interpretation. \n",
    "# In contrast, k-nearest neighbors relies solely on the proximity of each data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00360fc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 & 5 Modeling: $k$-nearest neighbors\n",
    "\n",
    "### Train-test split your data:\n",
    "\n",
    "Your features should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7239cca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3347, 44), (837, 44), (3347,), (837,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=42,  test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba7bc7be-5442-43e6-ba35-d1c625801372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hand\n",
       "1    84.642964\n",
       "2    10.815656\n",
       "3     4.272483\n",
       "0     0.268898\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.value_counts()\n",
    "y_train.value_counts(normalize=True).mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee305c92-05e8-43fd-8c88-aa36aff54686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hand\n",
       "1    84.707288\n",
       "2    10.752688\n",
       "3     4.301075\n",
       "0     0.238949\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.value_counts()\n",
    "y_test.value_counts(normalize=True).mul(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f7e27",
   "metadata": {},
   "source": [
    "#### Create and fit four separate $k$-nearest neighbors models: \n",
    "- one with $k = 3$\n",
    "- one with $k = 5$\n",
    "- one with $k = 15$\n",
    "- one with $k = 25$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2664f0d1-ffb5-43a8-b22a-c9b089a6fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3,5,15,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d00f5835-b296-4c3f-b0bb-a854c6fc7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K= 3, cross validation score: 0.8064\n",
      " K= 5, cross validation score: 0.8341\n",
      " K= 15, cross validation score: 0.8463\n",
      " K= 25, cross validation score: 0.8466\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_k(X, y, k_values):\n",
    "    # Calculate accuracy for each k\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        cross_score = cross_val_score(knn, X, y, cv=5).mean()\n",
    "        print(f\" K= {k}, cross validation score: {cross_score:.4f}\")\n",
    "find_optimal_k(X, y, k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6f202",
   "metadata": {},
   "source": [
    "### Evaluate your models:\n",
    "\n",
    "Evaluate each of your four models on the training and testing sets, and interpret the four scores. \n",
    "\n",
    "Are any of your models overfit or underfit? \n",
    "\n",
    "Do any of your models beat the baseline accuracy rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2426665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3\n",
      "Training Score: 0.8611\n",
      "Test Score: 0.8220\n",
      "\n",
      "K = 5\n",
      "Training Score: 0.8488\n",
      "Test Score: 0.8399\n",
      "\n",
      "K = 15\n",
      "Training Score: 0.8464\n",
      "Test Score: 0.8471\n",
      "\n",
      "K = 25\n",
      "Training Score: 0.8464\n",
      "Test Score: 0.8471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def k_model(k_list):\n",
    "    for k in k_list:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        print(f'K = {k}')\n",
    "\n",
    "        # Fit model\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # Score model\n",
    "        print(f\"Training Score: {knn.score(X_train, y_train):.4f}\")\n",
    "        print(f\"Test Score: {knn.score(X_test, y_test):.4f}\\n\")\n",
    "\n",
    "# Call function with consistently formatted data\n",
    "k_model(k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "126b8d14-4300-4666-b961-3bae5e00e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline = 0.8487\n",
    "# K = 15, 25 causes the model to overfit\n",
    "# No model beats the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488dc25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 & 5 Modeling: logistic regression\n",
    "\n",
    "#### Create and fit four separate logistic regression models: one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "Note: You can use the same train and test data as used above with kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "addc266d-c56c-4e32-b4e5-33412dde7511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LASSO Model (alpha=1.0) Train Score: 0.8464\n",
      "'LASSO Model (alpha=1.0) Test Score: 0.8471\n",
      "\n",
      "'LASSO Model (alpha=10.0) Train Score: 0.8458\n",
      "'LASSO Model (alpha=10.0) Test Score: 0.8471\n",
      "\n",
      "'Ridge Model (alpha=1.0) Train Score: 0.8464\n",
      "'Ridge Model (alpha=1.0) Test Score: 0.8471\n",
      "\n",
      "'Ridge Model (alpha=10.0) Train Score: 0.8464\n",
      "'Ridge Model (alpha=10.0) Test Score: 0.8471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = [1, 10]\n",
    "C_values = [1 / alpha for alpha in alphas]\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "# LASSO (L1 penalty) logistic regression models\n",
    "for C in C_values:\n",
    "    lasso_model = LogisticRegression(penalty='l1', C=C, solver='liblinear')\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    print(f\"'LASSO Model (alpha={1 / C}) Train Score: {lasso_model.score(X_train,y_train):.4f}\")\n",
    "    print(f\"'LASSO Model (alpha={1 / C}) Test Score: {lasso_model.score(X_test,y_test):.4f}\\n\")\n",
    "\n",
    "# Ridge (L2 penalty) logistic regression models\n",
    "for C in C_values:\n",
    "    ridge_model = LogisticRegression(penalty='l2', C=C, solver='liblinear')\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    print(f\"'Ridge Model (alpha={1 / C}) Train Score: {ridge_model.score(X_train,y_train):.4f}\")\n",
    "    print(f\"'Ridge Model (alpha={1 / C}) Test Score: {ridge_model.score(X_test,y_test):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703eecea",
   "metadata": {},
   "source": [
    "### Evaluate your models:\n",
    "\n",
    "Evaluate each of your four models on the training and testing sets, and interpret the four scores. \n",
    "\n",
    "Are any of your models overfit or underfit? \n",
    "\n",
    "Do any of your models beat the baseline accuracy rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d42c9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline = 0.8487\n",
    "# Alpha = 1,10 for Ridge and Lasso cause the model to overfit\n",
    "# No model beats the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a746e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "Are any of your models worth moving forward with? \n",
    "\n",
    "What are the \"best\" models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1eeac9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From K-nearest neighbors with k = 3, 5, 15, 25 and Logistic Regression with L1 or L2 penalty and alpha = 1, 10,\n",
    "# the best model is K-nearest neighbors with k = 5, achieving an accuracy score of 0.8399.\n",
    "# Although this isnâ€™t the highest score, higher scores lead to overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
